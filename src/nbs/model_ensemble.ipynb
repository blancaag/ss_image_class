{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "svmem(total=17179869184, available=6309834752, percent=63.3, used=16002539520, free=33968128, active=6469238784, inactive=6275866624, wired=3257434112)\n",
      "2.0.8\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../utils/')\n",
    "\n",
    "import libraries\n",
    "from libraries import *\n",
    "import utils_functions\n",
    "from utils_functions import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "reload(libraries)\n",
    "from libraries import *\n",
    "reload(utils_functions)\n",
    "from utils_functions import *\n",
    "\n",
    "# checking\n",
    "print(get_available_gpus())\n",
    "print(psutil.virtual_memory())\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/resnet_50\n",
      "(160,)\n"
     ]
    }
   ],
   "source": [
    "target_size = (256, 256) #(512, 512)\n",
    "\n",
    "output = '../output'\n",
    "data = 'compressed_data'\n",
    "cd_path = join(join(output, data), str(target_size[0]) + '_' + str(target_size[1]))\n",
    "\n",
    "# loading test data\n",
    "\n",
    "x_test = load_array(join(cd_path, 'x_test'))\n",
    "y_test = load_array(join(cd_path, 'y_test'))\n",
    "\n",
    "# models to include\n",
    "\n",
    "models_list = ['resnet_50', 'inception_v3', 'xception', 'mobilenet', \n",
    "               'vgg_16', 'vgg_19',\n",
    "               'densenet_121', 'densenet_161', 'densenet_169']\n",
    "models_list = ['resnet_50']\n",
    "\n",
    "preds = np.empty((0,))\n",
    "for i in models_list:\n",
    "    print(join(output, i))\n",
    "    model_ouput = join(output, i)\n",
    "    pred = load_array(join(join(output, i), 'predictions'))\n",
    "    preds = np.append(preds, pred)\n",
    "\n",
    "print(preds.shape)\n",
    "# preds_mean = preds.mean(axis=0)\n",
    "# preds_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "_FLOATX = 'float32'\n",
    "_EPSILON = 10e-8\n",
    "_IMAGE_DATA_FORMAT = 'channels_last'\n",
    "\n",
    "\n",
    "def epsilon():\n",
    "    \"\"\"Returns the value of the fuzz factor used in numeric expressions.\n",
    "    # Returns\n",
    "        A float.\n",
    "    # Example\n",
    "    \"\"\"\n",
    "    return _EPSILON\n",
    "\n",
    "def _to_tensor(x, dtype):\n",
    "    \"\"\"Convert the input `x` to a tensor of type `dtype`.\n",
    "    # Arguments\n",
    "        x: An object to be converted (numpy array, list, tensors).\n",
    "        dtype: The destination type.\n",
    "    # Returns\n",
    "        A tensor.\n",
    "    \"\"\"\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    if x.dtype != dtype:\n",
    "        x = tf.cast(x, dtype)\n",
    "    return x\n",
    "\n",
    "def clip(x, min_value, max_value):\n",
    "    \"\"\"Element-wise value clipping.\n",
    "    # Arguments\n",
    "        x: Tensor or variable.\n",
    "        min_value: Python float or integer.\n",
    "        max_value: Python float or integer.\n",
    "    # Returns\n",
    "        A tensor.\n",
    "    \"\"\"\n",
    "    if max_value is not None and max_value < min_value:\n",
    "        max_value = min_value\n",
    "    if max_value is None:\n",
    "        max_value = np.inf\n",
    "    min_value = _to_tensor(min_value, x.dtype.base)\n",
    "    max_value = _to_tensor(max_value, x.dtype.base)\n",
    "    return tf.clip_by_value(x, min_value, max_value)\n",
    "\n",
    "def binary_crossentropy(target, output, from_logits=False):\n",
    "    \"\"\"Binary crossentropy between an output tensor and a target tensor.\n",
    "    # Arguments\n",
    "        target: A tensor with the same shape as `output`.\n",
    "        output: A tensor.\n",
    "        from_logits: Whether `output` is expected to be a logits tensor.\n",
    "            By default, we consider that `output`\n",
    "            encodes a probability distribution.\n",
    "    # Returns\n",
    "        A tensor.\n",
    "    \"\"\"\n",
    "    _epsilon = _EPSILON = 10e-8\n",
    "    # Note: tf.nn.sigmoid_cross_entropy_with_logits\n",
    "    # expects logits, Keras expects probabilities.\n",
    "    if not from_logits:\n",
    "        # transform back to logits\n",
    "#         _epsilon = _to_tensor(epsilon(), output.dtype.base) # HERE: .base_dtype for .base\n",
    "        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n",
    "        output = tf.log(output / (1 - output))\n",
    "\n",
    "    return tf.nn.sigmoid_cross_entropy_with_logits(labels=target,\n",
    "                                                   logits=output)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(clip(y_true * y_pred, 0, 1))) # HERE K.clip for clip\n",
    "    possible_positives = K.sum(K.round(clip(y_true, 0, 1)))      # HERE K.clip for clip\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(clip(y_true * y_pred, 0, 1)))   # HERE K.clip for clip\n",
    "    predicted_positives = K.sum(K.round(clip(y_pred, 0, 1)))       # HERE K.clip for clip\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    \"\"\"Computes the F score.\n",
    "\n",
    "    The F score is the weighted harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    \"\"\"\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(clip(y_true, 0, 1))) == 0:       # HERE K.clip for clip\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
    "\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    \"\"\"\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n",
    "\n",
    "def kullback_leibler_divergence(y_true, y_pred):\n",
    "    \"\"\"Computes the KLdivergence between prediction and target values.\n",
    "    \"\"\"\n",
    "    y_true = clip(y_true, K.epsilon(), 1)           # HERE K.clip for clip\n",
    "    y_pred = clip(y_pred, K.epsilon(), 1)           # HERE K.clip for clip\n",
    "    return K.mean(K.sum(y_true * K.log(y_true / y_pred), axis=-1))\n",
    "\n",
    "def matthews_correlation(y_true, y_pred):\n",
    "    \"\"\"Matthews correlation metric.\n",
    "\n",
    "    It is only computed as a batch-wise average, not globally.\n",
    "\n",
    "    Computes the Matthews correlation coefficient measure for quality\n",
    "    of binary classification problems.\n",
    "    \"\"\"\n",
    "    y_pred_pos = K.round(clip(y_pred, 0, 1))     # HERE K.clip for clip\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(clip(y_true, 0, 1))            # HERE K.clip for clip\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_crossentropy\n",
      "binary_accuracy\n",
      "recall\n",
      "precision\n",
      "fbeta_score\n",
      "fmeasure\n",
      "hinge\n",
      "squared_hinge\n",
      "kullback_leibler_divergence\n",
      "poisson\n",
      "cosine_proximity\n",
      "matthews_correlation\n",
      "Metrics for the validation set\n",
      "binary_crossentropy Tensor(\"logistic_loss_29:0\", shape=(160,), dtype=float64)\n",
      "binary_accuracy Tensor(\"Mean_74:0\", shape=(), dtype=float32)\n",
      "recall Tensor(\"truediv_148:0\", shape=(), dtype=float64)\n",
      "precision Tensor(\"truediv_149:0\", shape=(), dtype=float64)\n",
      "fbeta_score Tensor(\"truediv_152:0\", shape=(), dtype=float64)\n",
      "fmeasure Tensor(\"truediv_155:0\", shape=(), dtype=float64)\n",
      "hinge Tensor(\"Mean_75:0\", shape=(), dtype=float64)\n",
      "squared_hinge Tensor(\"Mean_76:0\", shape=(), dtype=float64)\n",
      "kullback_leibler_divergence Tensor(\"Mean_77:0\", shape=(), dtype=float64)\n",
      "poisson Tensor(\"Mean_78:0\", shape=(), dtype=float64)\n",
      "cosine_proximity Tensor(\"Neg_9:0\", shape=(), dtype=float64)\n",
      "matthews_correlation Tensor(\"truediv_157:0\", shape=(), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.eval of <tf.Tensor 'truediv_158:0' shape=() dtype=float64>>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_func = [binary_crossentropy, binary_accuracy, recall, precision, \n",
    "               fbeta_score, fmeasure, hinge, squared_hinge, kullback_leibler_divergence,\n",
    "               poisson, cosine_proximity, matthews_correlation]\n",
    "\n",
    "metrics = {}\n",
    "for i in metric_func:\n",
    "    print(str(i.__name__))\n",
    "    metrics[i.__name__] = i(preds, y_test)\n",
    "\n",
    "print(\"Metrics for the validation set\")\n",
    "\n",
    "for i, j in metrics.items():\n",
    "    print(i, j)\n",
    "\n",
    "p = precision(preds, y_test)\n",
    "p.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "loss = metrics['binary_crossentropy']\n",
    "np.mean(loss.eval(session=sess))\n",
    "\n",
    "sess = tf.Session()\n",
    "loss = metrics['binary_accuracy']\n",
    "np.mean(loss.eval(session=sess))\n",
    "\n",
    "\n",
    "# print(preds)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
